{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {
    "editable": true,
    "id": "9316da0d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## **챗 모델과 Message를 사용해 간단한 LLM 애플리케이션 구축하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "I1APsrLauEiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1APsrLauEiT",
    "outputId": "07352eb4-b720-42c9-cc5d-7778166cb1fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e1b785-ee30-49d7-8b75-a6f75d26c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {
    "id": "e5558ca9"
   },
   "source": [
    "## 언어 모델 사용하기\n",
    "\n",
    "LangChain은 다양한 언어 모델을 지원하며, 이들을 서로 교체하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b41234",
   "metadata": {
    "id": "e4b41234"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "# model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {
    "id": "ca5642ff"
   },
   "source": [
    "ChatModels은 LangChain Runnables의 인스턴스로, 표준화된 인터페이스를 통해 상호작용할 수 있습니다. 모델을 간단히 호출하려면 `.invoke` 메서드에 Messages 목록을 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc68f2-e940-41af-b949-9bec65100923",
   "metadata": {},
   "source": [
    "## 메시지 (Messages)\n",
    "\n",
    "메시지(Messages) 는 LangChain에서 모델이 사용하는 컨텍스트의 기본 단위입니다.\n",
    "이들은 모델의 입력(input) 과 출력(output) 을 나타내며, LLM과의 상호작용에서 대화의 상태(state)를 표현하는 데 필요한 콘텐츠(content) 와 메타데이터(metadata) 를 함께 포함합니다.\n",
    "\n",
    "메시지는 다음 요소들로 구성됩니다:\n",
    "\n",
    "- Role (역할)\n",
    "→ 메시지의 유형을 식별합니다. 예: system, user, assistant 등  \n",
    "- Content (내용)\n",
    "→ 메시지의 실제 내용으로, 텍스트뿐만 아니라 이미지, 오디오, 문서 등 다양한 형식을 포함할 수 있습니다.  \n",
    "- Metadata (메타데이터)\n",
    "→ 선택적(optional) 필드로, 응답 정보(response info), 메시지 ID, 토큰 사용량(token usage) 등 부가 정보를 담습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2481f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b2481f0",
    "outputId": "4323da7b-9ebf-4ed3-f3b1-5cf182dafd16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain이 무엇인가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 40, 'total_tokens': 184, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnYpsV8qUiULls6PhszZbNC1dPSf4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--22cc70dd-65d6-4372-a87c-067be90ca2b7-0', usage_metadata={'input_tokens': 40, 'output_tokens': 144, 'total_tokens': 184, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 메시지 목록을 생성\n",
    "messages = [\n",
    "    # 시스템 메시지: 모델에게 수행할 작업이나 역할을 지시합니다.\n",
    "    SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "    # 사용자 메시지: 사용자가 모델에 보낼 실제 입력 내용입니다.\n",
    "    HumanMessage(\"What is LangChain?\"),\n",
    "]\n",
    "\n",
    "answer = model.invoke(messages)  # `invoke` 메서드를 사용해 모델을 호출합니다.\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "CGRBL2IrZcsP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGRBL2IrZcsP",
    "outputId": "2d3464d8-e61c-4972-a3d2-c3de59493a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain이 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "answer.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cbd960-d92a-42ba-89c5-a4a664bc7b88",
   "metadata": {},
   "source": [
    "### 텍스트 프롬프트 (Text prompts)\n",
    "\n",
    "**텍스트 프롬프트(Text prompts)** 는 단순한 **문자열(string)** 형태로 제공됩니다.  \n",
    "대화 기록(conversation history)을 유지할 필요가 없는 **단순한 생성 작업**(예: 요약, 문장 생성, 번역 등)에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1034d669-aa6e-4980-9ada-c4f97e63e5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "데이터의 바다에서 자란 말의 씨앗  \n",
      "확률의 길로 문장을 엮고 노래하네  \n",
      "학습의 밤을 지나 비추는 작은 빛  \n",
      "물음이 다가오면 숨 쉬듯 대답의 길을 열고  \n",
      "우리 말과 생각을 잇는 조용한 다리, LLM\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"LLM 에 관한 시를 5줄 이내로 지어주세요.\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ae698-b258-41f2-bff3-591e871781ae",
   "metadata": {},
   "source": [
    "### 딕셔너리 형식 (Dictionary format)\n",
    "\n",
    "OpenAI의 **Chat Completions 포맷**을 사용해 메시지를 **딕셔너리 형태로 직접 지정**할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b65209b-6307-414f-a612-d8cfa114e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain이 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 형식\n",
    "answer = model.invoke([\n",
    "    {\"role\": \"system\", \"content\": \"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is LangChain?\"},\n",
    "])\n",
    "answer.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101b1e5-00e3-44cd-99e8-622c9076964f",
   "metadata": {},
   "source": [
    "--------------\n",
    "## 메시지 유형 (Message types)\n",
    "\n",
    "* **System message (시스템 메시지)**\n",
    "  → 모델이 어떻게 행동해야 하는지 지시하고, 상호작용의 **맥락(context)** 을 제공합니다.  \n",
    "* **Human message (사용자 메시지)**\n",
    "  → 사용자의 입력을 나타내며, 모델과의 **대화(interaction)** 를 구성합니다.  \n",
    "* **AI message (AI 메시지)**\n",
    "  → 모델이 생성한 응답으로, **텍스트 내용(text content)** 뿐 아니라\n",
    "  **도구 호출(tool calls)** 및 **메타데이터(metadata)** 를 포함할 수 있습니다.  \n",
    "* **Tool message (도구 메시지)**\n",
    "  → 모델이 호출한 **도구의 실행 결과(outputs)** 를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b244e713-c236-43e7-b2d6-efa2b9764527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- FastAPI나 Django REST Framework 같은 프레임워크로 프로젝트를 시작합니다.\n",
      "- 자원(예: /users, /items)과 CRUD를 HTTP 메서드로 매핑해 REST 엔드포인트를 설계합니다.\n",
      "- 입력/출력을 Pydantic(또는 DRF Serializer)으로 검증하고 직렬화합니다.\n",
      "- SQLAlchemy나 Django ORM으로 데이터를 저장하고 비즈니스 로직을 구현합니다.\n",
      "- JWT 인증/권한, 테스트 작성, 컨테이너 배포(Gunicorn/uvicorn, Docker)로 운영을 준비합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "당신은 웹 프레임워크에 전문성을 가진 시니어 Python 개발자입니다.\n",
    "설명은 간결하게 5줄 이내로 설명하세요.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"REST API를 어떻게 만들 수 있나요?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd416a6-4bb9-4c1d-a43a-d52c5f8a4b5d",
   "metadata": {},
   "source": [
    "### AI 메시지 (AI Message)\n",
    "\n",
    "**AIMessage** 는 **모델 호출(model invocation)** 의 **출력 결과**를 나타냅니다.\n",
    "이 메시지에는 다음과 같은 요소들을 포함할 수 있습니다:\n",
    "\n",
    "* **멀티모달 데이터 (Multimodal data)** — 텍스트뿐만 아니라 이미지, 오디오 등의 출력\n",
    "* **도구 호출 (Tool calls)** — 모델이 외부 도구를 실행한 기록\n",
    "* **제공자별 메타데이터 (Provider-specific metadata)** — 모델 제공자(OpenAI, Anthropic 등)에 따라 추가로 제공되는 정보\n",
    "\n",
    "이러한 메타데이터는 나중에 접근하거나 분석할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45de4fe-764a-4da1-90bf-c5ecf06da539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='데이터를 통해 학습하고 판단·문제 해결을 보조하는, 인간 지능의 일부를 모방한 컴퓨팅 기술.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 424, 'prompt_tokens': 16, 'total_tokens': 440, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnYqONLIWlLASVldGeZDKOpTTb9dT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d971c81b-fcc6-4f79-a544-9d398b24b665-0', usage_metadata={'input_tokens': 16, 'output_tokens': 424, 'total_tokens': 440, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"AI에 대해서 한줄로 설명해줘.\")\n",
    "print(type(response))  \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb097b8e-c693-4957-a33f-db56b6b995ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "4입니다. 다른 수학 문제도 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# AI 메시지를 수동으로 생성 (예: 대화 기록에 추가하기 위해)\n",
    "ai_msg = AIMessage(\"그 질문에 기꺼이 도움을 드리겠습니다!\")\n",
    "\n",
    "# 대화 기록에 추가\n",
    "messages = [\n",
    "    SystemMessage(\"당신은 도움이 되는 어시스턴트입니다.\"),\n",
    "    HumanMessage(\"저를 도와주실 수 있나요?\"),\n",
    "    ai_msg,  # 모델이 이전에 응답한 것처럼 삽입\n",
    "    HumanMessage(\"좋아요! 그럼 2 + 2는 얼마인가요?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a4174-9202-43d4-b458-55c5f67463ed",
   "metadata": {},
   "source": [
    "### 토큰 사용량 (Token usage)\n",
    "\n",
    "**AIMessage** 객체는 `usage_metadata` 필드에\n",
    "**토큰 사용량(token counts)** 및 기타 **사용 관련 메타데이터(metadata)** 를 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed023e1c-0c69-42d8-99d9-2fb0ab1ade9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 8,\n",
       " 'output_tokens': 311,\n",
       " 'total_tokens': 319,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 256}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"Hello!\")\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf8e88-819c-445f-ae28-92f05e549cb4",
   "metadata": {},
   "source": [
    "### batch interface 이용 여러개의 메시지 일괄 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f26b9c15-aefd-4908-a3c8-0d558f39b2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='LangChain이란 무엇인가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 40, 'total_tokens': 249, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnYqbMldvrdg5Nphn3NOWFm6uEBNj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--56c074f9-de59-4584-933b-c50bac30ef5b-0', usage_metadata={'input_tokens': 40, 'output_tokens': 209, 'total_tokens': 249, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}),\n",
       " AIMessage(content='LangChain은 어떻게 작동합니까?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 41, 'total_tokens': 251, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnYqbcVPvy5dllCSvuoHIpovlvcgz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--15bcc71a-93d8-448b-8251-f22683351fc9-0', usage_metadata={'input_tokens': 41, 'output_tokens': 210, 'total_tokens': 251, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}),\n",
       " AIMessage(content='LangChain의 주요 특징은 무엇인가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 211, 'prompt_tokens': 44, 'total_tokens': 255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnYqcleydu5sd0l0nW648Ff1vnLLf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8712062f-b725-4f6e-a88d-4985eb58c9aa-0', usage_metadata={'input_tokens': 44, 'output_tokens': 211, 'total_tokens': 255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메시지 목록을 생성\n",
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"What is LangChain?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"How does LangChain work?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"What are the key features of LangChain?\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "# `model.batch()`을 사용하여 여러 개의 메시지를 한 번에 처리\n",
    "# LangChain은 각 입력을 독립된 invoke() 호출처럼 처리\n",
    "answers = model.batch(batch_messages)\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018da27f-d225-4f9d-aa94-6d6cabce66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번역 1: LangChain이란 무엇인가요?\n",
      "번역 2: LangChain은 어떻게 작동합니까?\n",
      "번역 3: LangChain의 주요 특징은 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for idx, ans in enumerate(answers):\n",
    "    print(f\"번역 {idx + 1}: {ans.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d335ec-dcc9-4b4e-a714-74ab509d71cd",
   "metadata": {},
   "source": [
    "### stream inferface 를 이용한 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76047bf-3c63-4460-9f5d-f991aa6472a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lang\n",
      "Chain\n",
      "은\n",
      " L\n",
      "LM\n",
      "(\n",
      "대\n",
      "형\n",
      " 언\n",
      "어\n",
      " 모델\n",
      ")\n",
      " 기반\n",
      " 애\n",
      "플\n",
      "리\n",
      "케\n",
      "이션\n",
      "을\n",
      " easier\n",
      "하게\n",
      " 만들\n",
      "기\n",
      " 위한\n",
      " 프\n",
      "레\n",
      "임\n",
      "워크\n",
      "로\n",
      ",\n",
      " 여러\n",
      " 구성\n",
      " 요소\n",
      "를\n",
      " 표\n",
      "준\n",
      "화\n",
      "해\n",
      " 체\n",
      "인\n",
      "처럼\n",
      " 연결\n",
      "하고\n",
      " 도\n",
      "구\n",
      "를\n",
      " 활용\n",
      "하도록\n",
      " 돕\n",
      "습니다\n",
      ".\n",
      " 주요\n",
      " 기능\n",
      "은\n",
      " 다음\n",
      "과\n",
      " 같습니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 프\n",
      "롬\n",
      "프트\n",
      " 관리\n",
      "와\n",
      " 템\n",
      "플\n",
      "릿\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " Prompt\n",
      "Template\n",
      "/\n",
      "Chat\n",
      "Prompt\n",
      "Template\n",
      " 등을\n",
      " 이용\n",
      "해\n",
      " 프\n",
      "롬\n",
      "프트\n",
      "를\n",
      " 체\n",
      "계\n",
      "적으로\n",
      " 구성\n",
      "하고\n",
      " 재\n",
      "사용\n",
      "할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " 단\n",
      "일\n",
      " 프\n",
      "롬\n",
      "프트\n",
      ",\n",
      " 다\n",
      "중\n",
      " 라\n",
      "운\n",
      "드\n",
      " 프\n",
      "롬\n",
      "프트\n",
      ",\n",
      " Few\n",
      "-shot\n",
      " 프\n",
      "롬\n",
      "프트\n",
      " 등을\n",
      " 쉽게\n",
      " 만들\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 체\n",
      "인\n",
      "(\n",
      "Chain\n",
      ")\n",
      " 기반\n",
      " 처리\n",
      " 파\n",
      "이\n",
      "프\n",
      "라인\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " L\n",
      "LM\n",
      "Chain\n",
      ",\n",
      " Sequential\n",
      "Chain\n",
      " 등\n",
      "으로\n",
      " 여러\n",
      " 단\n",
      "계를\n",
      " 순\n",
      "서\n",
      "대로\n",
      " 연결\n",
      "해\n",
      " 복\n",
      "잡\n",
      "한\n",
      " 처리\n",
      " 흐\n",
      "름\n",
      "을\n",
      " 구성\n",
      "합니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " 다\n",
      "단\n",
      "계\n",
      " 의\n",
      "사\n",
      "결\n",
      "정\n",
      ",\n",
      " 데이터\n",
      " 가\n",
      "공\n",
      ",\n",
      " 출력\n",
      " 포\n",
      "맷\n",
      "팅\n",
      " 등을\n",
      " 한\n",
      " 묶\n",
      "음\n",
      "으로\n",
      " 관리\n",
      "합니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 에\n",
      "이\n",
      "전\n",
      "트\n",
      "와\n",
      " 도\n",
      "구\n",
      "(T\n",
      "ool\n",
      ")\n",
      " 시스템\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 에\n",
      "이\n",
      "전\n",
      "트\n",
      "가\n",
      " 상황\n",
      "에\n",
      " 맞\n",
      "춰\n",
      " 도\n",
      "구\n",
      "를\n",
      " 선택\n",
      "하고\n",
      " 호출\n",
      "하도록\n",
      " 구성\n",
      "할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " API\n",
      " 호출\n",
      ",\n",
      " 데이터\n",
      "베\n",
      "이스\n",
      " 질\n",
      "의\n",
      ",\n",
      " 파일\n",
      " 시스템\n",
      " 접근\n",
      " 등\n",
      " 외\n",
      "부\n",
      " 도\n",
      "구\n",
      "와\n",
      "의\n",
      " 상\n",
      "호\n",
      "작\n",
      "용\n",
      "을\n",
      " 추\n",
      "상\n",
      "화\n",
      "하여\n",
      " 구현\n",
      "이\n",
      " 쉬\n",
      "워\n",
      "집\n",
      "니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 메\n",
      "모\n",
      "리\n",
      "와\n",
      " 대\n",
      "화\n",
      " 컨\n",
      "텍\n",
      "스트\n",
      " 관리\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 컨\n",
      "텍\n",
      "스트\n",
      " 유지\n",
      "(memory\n",
      ")\n",
      " 기능\n",
      "으로\n",
      " 대\n",
      "화를\n",
      " 기억\n",
      "하고\n",
      " 요\n",
      "약\n",
      "하는\n",
      " 메\n",
      "모\n",
      "리\n",
      " 모\n",
      "듈\n",
      "을\n",
      " 제공합니다\n",
      "(\n",
      "예\n",
      ":\n",
      " Conversation\n",
      "Buffer\n",
      "Memory\n",
      ",\n",
      " Conversation\n",
      "Summary\n",
      "Memory\n",
      " 등\n",
      ").\n",
      "\n",
      " \n",
      " -\n",
      " 롱\n",
      "텀\n",
      " 컨\n",
      "텍\n",
      "스트\n",
      " 관리\n",
      " 및\n",
      " 대\n",
      "화\n",
      " 흐\n",
      "름\n",
      "의\n",
      " 자연\n",
      "스\n",
      "러운\n",
      " 연\n",
      "속\n",
      "성\n",
      " 확보\n",
      "에\n",
      " 활용\n",
      "됩니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 데이터\n",
      " 소\n",
      "스\n",
      " 로\n",
      "딩\n",
      " 및\n",
      " 전\n",
      "처\n",
      "리\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 텍\n",
      "스트\n",
      "/\n",
      "문\n",
      "서\n",
      " 로\n",
      "더\n",
      "(Document\n",
      " Load\n",
      "ers\n",
      ")\n",
      "로\n",
      " 다양한\n",
      " 파일\n",
      " 형\n",
      "식\n",
      "이나\n",
      " 웹\n",
      " 콘텐츠\n",
      "를\n",
      " 불\n",
      "러\n",
      "와\n",
      " 처리\n",
      "할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " PDF\n",
      ",\n",
      " 텍\n",
      "스트\n",
      ",\n",
      " CSV\n",
      ",\n",
      " JSON\n",
      " 등\n",
      " 여러\n",
      " 형\n",
      "식을\n",
      " 지원\n",
      "합니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 벡\n",
      "터\n",
      " 스\n",
      "토\n",
      "어\n",
      " 기반\n",
      "의\n",
      " 검색\n",
      "(R\n",
      "AG\n",
      ")\n",
      "\n",
      " \n",
      " -\n",
      " 임\n",
      "베\n",
      "딩\n",
      "을\n",
      " 이용\n",
      "해\n",
      " 벡\n",
      "터\n",
      " 저장\n",
      "소\n",
      "(Vector\n",
      "Store\n",
      ")에\n",
      " 문\n",
      "서를\n",
      " 인\n",
      "덱\n",
      "싱\n",
      "하고\n",
      ",\n",
      " 질\n",
      "의\n",
      "에\n",
      " 대해\n",
      " 유\n",
      "사\n",
      "도\n",
      " 기반\n",
      "으로\n",
      " 문\n",
      "서를\n",
      " 검색\n",
      "한\n",
      " 뒤\n",
      " L\n",
      "LM\n",
      "과\n",
      " 함께\n",
      " 답\n",
      "을\n",
      " 구성\n",
      "합니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " FA\n",
      "ISS\n",
      ",\n",
      " Ch\n",
      "roma\n",
      ",\n",
      " Pine\n",
      "cone\n",
      " 등\n",
      " 다양한\n",
      " 벡\n",
      "터\n",
      " 데이터\n",
      "베\n",
      "이스\n",
      "를\n",
      " 추\n",
      "상\n",
      "화\n",
      "하여\n",
      " 사용할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 구성\n",
      " 가능한\n",
      " 실행\n",
      " 엔\n",
      "진\n",
      " 및\n",
      " 성\n",
      "능\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 비\n",
      "동\n",
      "기\n",
      "/\n",
      "스트\n",
      "리\n",
      "밍\n",
      " 출력\n",
      ",\n",
      " 병\n",
      "렬\n",
      " 실행\n",
      " 등\n",
      " 런\n",
      "타\n",
      "임\n",
      " 성\n",
      "능\n",
      " 옵션\n",
      "을\n",
      " 지원\n",
      "합니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " 여러\n",
      " 체\n",
      "인\n",
      "과\n",
      " 도\n",
      "구\n",
      "를\n",
      " 유\n",
      "연\n",
      "하게\n",
      " 결\n",
      "합\n",
      "하여\n",
      " 복\n",
      "잡\n",
      "한\n",
      " 상\n",
      "호\n",
      "작\n",
      "용\n",
      "을\n",
      " 구현\n",
      "할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " Lang\n",
      "Chain\n",
      "Hub\n",
      " 및\n",
      " 생\n",
      "태\n",
      "계\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " Prom\n",
      "pts\n",
      ",\n",
      " Chains\n",
      ",\n",
      " Tools\n",
      " 등의\n",
      " 공유\n",
      " 자\n",
      "원\n",
      "(H\n",
      "ub\n",
      ")을\n",
      " 이용\n",
      "해\n",
      " 재\n",
      "사용\n",
      " 가능한\n",
      " 구성\n",
      " 요소\n",
      "를\n",
      " 쉽게\n",
      " 찾아\n",
      " 사용할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " Python\n",
      "과\n",
      " Java\n",
      "Script\n",
      "(\n",
      "또\n",
      "는\n",
      " Type\n",
      "Script\n",
      ")\n",
      " 버\n",
      "전\n",
      " 모두\n",
      "에서\n",
      " 사용\n",
      " 가능\n",
      "하며\n",
      ",\n",
      " 서로\n",
      " 다른\n",
      " 런\n",
      "타\n",
      "임\n",
      " 환경\n",
      "에서도\n",
      " 통\n",
      "일\n",
      "된\n",
      " 인터\n",
      "페\n",
      "이스\n",
      "를\n",
      " 제공합니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " 평가\n",
      "/\n",
      "테\n",
      "스트\n",
      " 및\n",
      " 도\n",
      "메\n",
      "인\n",
      " 확\n",
      "장\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 출력\n",
      " 평가\n",
      "(E\n",
      "vals\n",
      ")\n",
      "나\n",
      " 테스트\n",
      " 도\n",
      "구\n",
      "를\n",
      " 통해\n",
      " 체\n",
      "인\n",
      " 성\n",
      "능\n",
      "을\n",
      " 검\n",
      "증\n",
      "하고\n",
      " 개선\n",
      "할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      " \n",
      " -\n",
      " 여러\n",
      " 도\n",
      "메\n",
      "인\n",
      "에\n",
      " 걸\n",
      "친\n",
      " 프\n",
      "롬\n",
      "프트\n",
      "와\n",
      " 도\n",
      "구\n",
      "를\n",
      " 손\n",
      "쉽\n",
      "게\n",
      " 확\n",
      "장\n",
      "하고\n",
      " 재\n",
      "사용\n",
      "할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      "\n",
      "\n",
      "간\n",
      "단\n",
      "한\n",
      " 활용\n",
      " 예\n",
      "\n",
      "\n",
      "-\n",
      " 문\n",
      "서\n",
      " 기반\n",
      " Q\n",
      "&A\n",
      " 봇\n",
      ":\n",
      " 문\n",
      "서를\n",
      " 벡\n",
      "터\n",
      " 스\n",
      "토\n",
      "어\n",
      "에\n",
      " 인\n",
      "덱\n",
      "싱\n",
      "하고\n",
      ",\n",
      " 사용\n",
      "자의\n",
      " 질\n",
      "의\n",
      "에\n",
      " 대해\n",
      " 관련\n",
      " 문\n",
      "서를\n",
      " 검색\n",
      "한\n",
      " 뒤\n",
      " L\n",
      "LM\n",
      "으로\n",
      " 답\n",
      "변\n",
      " 생성\n",
      ".\n",
      "\n",
      "-\n",
      " 코드\n",
      " 보\n",
      "조\n",
      " 도\n",
      "우\n",
      "미\n",
      ":\n",
      " 코드\n",
      " 관련\n",
      " 도\n",
      "구\n",
      "를\n",
      " 에\n",
      "이\n",
      "전\n",
      "트\n",
      "에\n",
      " 연결\n",
      "하고\n",
      ",\n",
      " 필요\n",
      " 시\n",
      " 외\n",
      "부\n",
      " API\n",
      "나\n",
      " 파일\n",
      " 시스템\n",
      "에서\n",
      " 정보를\n",
      " 조회\n",
      "해\n",
      " 답\n",
      "변\n",
      " 제공\n",
      ".\n",
      "\n",
      "-\n",
      " 대\n",
      "화\n",
      "형\n",
      " 상담\n",
      " 봇\n",
      ":\n",
      " 메\n",
      "모\n",
      "리\n",
      " 기능\n",
      "으로\n",
      " 대\n",
      "화\n",
      " 맥\n",
      "락\n",
      "을\n",
      " 유지\n",
      "하고\n",
      ",\n",
      " 여러\n",
      " 체\n",
      "인을\n",
      " 통해\n",
      " 질문\n",
      " 분\n",
      "해\n",
      ",\n",
      " 정보\n",
      " 검색\n",
      ",\n",
      " 요\n",
      "약\n",
      ",\n",
      " 최\n",
      "종\n",
      " 응\n",
      "답\n",
      " 순\n",
      "으로\n",
      " 처리\n",
      ".\n",
      "\n",
      "\n",
      "필\n",
      "요\n",
      "하\n",
      "시면\n",
      " 한국\n",
      "어\n",
      " 예\n",
      "제\n",
      " 코드\n",
      "나\n",
      " 설치\n",
      " 방법\n",
      ",\n",
      " 간\n",
      "단\n",
      "한\n",
      " 프로젝트\n",
      " 시작\n",
      " 가\n",
      "이\n",
      "드를\n",
      " 함께\n",
      " 드\n",
      "릴\n",
      "게\n",
      "요\n",
      ".\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍 중에 받아온 chunk 들을 저장할 리스트\n",
    "chunks = []\n",
    "\n",
    "# 전체 메시지를 누적할 변수\n",
    "full_message = None\n",
    "\n",
    "# model.stream() 은 토큰(혹은 chunk)을 스트리밍 방식으로 하나씩 생성\n",
    "for chunk in model.stream(\"LangChain의 주요 기능은 무엇인가요?\"):\n",
    "    \n",
    "    chunks.append(chunk)\n",
    "    print(chunk.text)   # 현재 chunk 의 텍스트 출력 \n",
    "    \n",
    "    # full_message 에 chunk 를 누적\n",
    "    # 첫 chunk 일 경우 full_message 가 None 이므로 그대로 저장\n",
    "    # 이후부터는 기존 full_message 에 chunk 를 더해(concat) 전체 메시지를 구성\n",
    "    full_message = chunk if full_message is None else full_message + chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b2aaa89-6eed-4ed5-bf15-16d792e993b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='LangChain은 LLM(대형 언어 모델) 기반 애플리케이션을 easier하게 만들기 위한 프레임워크로, 여러 구성 요소를 표준화해 체인처럼 연결하고 도구를 활용하도록 돕습니다. 주요 기능은 다음과 같습니다.\\n\\n- 프롬프트 관리와 템플릿\\n  - PromptTemplate/ChatPromptTemplate 등을 이용해 프롬프트를 체계적으로 구성하고 재사용할 수 있습니다.\\n  - 단일 프롬프트, 다중 라운드 프롬프트, Few-shot 프롬프트 등을 쉽게 만들 수 있습니다.\\n\\n- 체인(Chain) 기반 처리 파이프라인\\n  - LLMChain, SequentialChain 등으로 여러 단계를 순서대로 연결해 복잡한 처리 흐름을 구성합니다.\\n  - 다단계 의사결정, 데이터 가공, 출력 포맷팅 등을 한 묶음으로 관리합니다.\\n\\n- 에이전트와 도구(Tool) 시스템\\n  - 에이전트가 상황에 맞춰 도구를 선택하고 호출하도록 구성할 수 있습니다.\\n  - API 호출, 데이터베이스 질의, 파일 시스템 접근 등 외부 도구와의 상호작용을 추상화하여 구현이 쉬워집니다.\\n\\n- 메모리와 대화 컨텍스트 관리\\n  - 컨텍스트 유지(memory) 기능으로 대화를 기억하고 요약하는 메모리 모듈을 제공합니다(예: ConversationBufferMemory, ConversationSummaryMemory 등).\\n  - 롱텀 컨텍스트 관리 및 대화 흐름의 자연스러운 연속성 확보에 활용됩니다.\\n\\n- 데이터 소스 로딩 및 전처리\\n  - 텍스트/문서 로더(Document Loaders)로 다양한 파일 형식이나 웹 콘텐츠를 불러와 처리할 수 있습니다.\\n  - PDF, 텍스트, CSV, JSON 등 여러 형식을 지원합니다.\\n\\n- 벡터 스토어 기반의 검색(RAG)\\n  - 임베딩을 이용해 벡터 저장소(VectorStore)에 문서를 인덱싱하고, 질의에 대해 유사도 기반으로 문서를 검색한 뒤 LLM과 함께 답을 구성합니다.\\n  - FAISS, Chroma, Pinecone 등 다양한 벡터 데이터베이스를 추상화하여 사용할 수 있습니다.\\n\\n- 구성 가능한 실행 엔진 및 성능\\n  - 비동기/스트리밍 출력, 병렬 실행 등 런타임 성능 옵션을 지원합니다.\\n  - 여러 체인과 도구를 유연하게 결합하여 복잡한 상호작용을 구현할 수 있습니다.\\n\\n- LangChainHub 및 생태계\\n  - Prompts, Chains, Tools 등의 공유 자원(Hub)을 이용해 재사용 가능한 구성 요소를 쉽게 찾아 사용할 수 있습니다.\\n  - Python과 JavaScript(또는 TypeScript) 버전 모두에서 사용 가능하며, 서로 다른 런타임 환경에서도 통일된 인터페이스를 제공합니다.\\n\\n- 평가/테스트 및 도메인 확장\\n  - 출력 평가(Evals)나 테스트 도구를 통해 체인 성능을 검증하고 개선할 수 있습니다.\\n  - 여러 도메인에 걸친 프롬프트와 도구를 손쉽게 확장하고 재사용할 수 있습니다.\\n\\n간단한 활용 예\\n- 문서 기반 Q&A 봇: 문서를 벡터 스토어에 인덱싱하고, 사용자의 질의에 대해 관련 문서를 검색한 뒤 LLM으로 답변 생성.\\n- 코드 보조 도우미: 코드 관련 도구를 에이전트에 연결하고, 필요 시 외부 API나 파일 시스템에서 정보를 조회해 답변 제공.\\n- 대화형 상담 봇: 메모리 기능으로 대화 맥락을 유지하고, 여러 체인을 통해 질문 분해, 정보 검색, 요약, 최종 응답 순으로 처리.\\n\\n필요하시면 한국어 예제 코드나 설치 방법, 간단한 프로젝트 시작 가이드를 함께 드릴게요.', additional_kwargs={}, response_metadata={'model_provider': 'openai', 'finish_reason': 'stop', 'model_name': 'gpt-5-nano-2025-08-07', 'service_tier': 'default'}, id='lc_run--81f7d4a1-fd7d-484c-8301-3bbf34706746', usage_metadata={'input_tokens': 16, 'output_tokens': 2530, 'total_tokens': 2546, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1664}}, chunk_position='last')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad55ad5-505f-4ff7-bbd9-d406c86eea55",
   "metadata": {},
   "source": [
    "### 도구 메시지 (Tool Message)\n",
    "\n",
    "도구 호출(tool calling)을 지원하는 모델의 경우,\n",
    "**AI 메시지(AIMessage)** 안에 **도구 호출 정보(tool calls)** 가 포함될 수 있습니다.\n",
    "\n",
    "**Tool Message(도구 메시지)** 는\n",
    "**단일 도구 실행의 결과(result)** 를 모델에게 다시 전달하기 위해 사용됩니다.\n",
    "\n",
    "또한, 도구는 직접 **`ToolMessage` 객체**를 생성하여\n",
    "실행 결과를 LangChain 에이전트나 모델로 반환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "856d1d23-58cc-4404-b289-5b15f25f9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "샌프란시스코는 맑습니다. 현재 기온은 화씨 72도(섭씨 약 22°C)예요. 더 자세한 오늘 전망이나 주간 예보가 필요하시면 말씀해 주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# 모델이 도구 호출을 수행한 후\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",                   # 호출된 도구 이름\n",
    "        \"args\": {\"location\": \"San Francisco\"},   # 도구에 전달된 인자\n",
    "        \"id\": \"call_123\"                         # 도구 호출 ID\n",
    "    }]\n",
    ")\n",
    "\n",
    "# 도구 실행 후 결과 메시지 생성\n",
    "weather_result = \"맑음, 72°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # 반드시 호출 ID와 일치해야 함\n",
    ")\n",
    "\n",
    "# 대화 이어가기\n",
    "messages = [\n",
    "    HumanMessage(\"샌프란시스코의 날씨는 어때?\"),\n",
    "    ai_message,     # 모델이 도구 호출을 요청한 메시지\n",
    "    tool_message,   # 도구 실행 결과를 모델에 전달\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)  # 모델이 도구 결과를 반영하여 후속 응답 생성\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630bc62-5019-4e07-af60-bc3226f468ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
